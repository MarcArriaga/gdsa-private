{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "#import cv2 as cv2\n",
    "from params import get_params\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "import numpy as np\n",
    "#from os import walk\n",
    "#from array import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from build_database import build_database\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['split'] = 'val'\n",
    "readfile = os.path.join(params['root'],params['database'],params['split'],'annotation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "labels = []\n",
    "f = open(readfile, 'r')\n",
    "for line in f:\n",
    "    image_lis, label = line[:-1].split('\\t')\n",
    "    image_list.append(image_lis)\n",
    "    labels.append(label)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list.pop(0)\n",
    "labels.pop(0)\n",
    "dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_list)): \n",
    "    dic[image_list[i]] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_val = {}\n",
    "k = 0\n",
    "for k in range(len(image_list)): \n",
    "    dic_val[k] = dic[image_list[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantes = {}\n",
    "for top in range(len(image_list)):\n",
    "    if relevantes.get(labels[top]):\n",
    "        relevantes[labels[top]]=relevantes[labels[top]]+1\n",
    "    else: \n",
    "        relevantes[labels[top]] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for image_name in image_list:\n",
    "\n",
    "        # Read image\n",
    "        lista.append(os.path.join(params['root'],params['database'],\n",
    "                                     params['split'],\n",
    "                                     'images',image_name.rstrip()+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "imagen = []\n",
    "final = []\n",
    "for i in range(len(image_list)):   \n",
    "    imagen.append(image.load_img(lista[i], target_size=(224, 224)))\n",
    "    final.append(image.img_to_array(imagen[i]))\n",
    "    final[i] = np.expand_dims(final[i], axis=0)\n",
    "    final[i] = preprocess_input(final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = []\n",
    "k = 0\n",
    "for k in range(len(image_list)):\n",
    "    salida.append(model.predict(final[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['splitt'] = 'test'\n",
    "readfile2 = os.path.join(params['root'],params['database'],params['splitt'],'annotation.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list2 = []\n",
    "labels2 = []\n",
    "f2 = open(readfile2, 'r')\n",
    "for line2 in f2:\n",
    "    image_lis2, label2 = line2[:-1].split('\\t')\n",
    "    image_list2.append(image_lis2)\n",
    "    labels2.append(label2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list2.pop(0)\n",
    "labels2.pop(0)\n",
    "dic2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i2 in range(len(image_list2)): \n",
    "    dic2[image_list2[i2]] = labels2[i2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_test = {}\n",
    "k2 = 0\n",
    "for k2 in range(len(image_list2)): \n",
    "    dic_test[k2] = dic2[image_list2[k2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista2 = []\n",
    "for image_name2 in image_list2:\n",
    "    lista2.append(os.path.join(params['root'],params['database'],\n",
    "                                     params['splitt'],\n",
    "                                     'images',image_name2.rstrip()+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2=0\n",
    "imagen2 = []\n",
    "final2 = []\n",
    "for i2 in range(len(image_list2)):   \n",
    "    imagen2.append(image.load_img(lista2[i2], target_size=(224, 224)))\n",
    "    final2.append(image.img_to_array(imagen2[i2]))\n",
    "    final2[i2] = np.expand_dims(final2[i2], axis=0)\n",
    "    final2[i2] = preprocess_input(final2[i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida2 = []\n",
    "k2 = 0\n",
    "for k2 in range(len(image_list2)):\n",
    "    salida2.append(model.predict(final2[k2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['splittr'] = 'train'\n",
    "readfile3 = os.path.join(params['root'],params['database'],params['splittr'],'annotation.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list3 = []\n",
    "labels3 = []\n",
    "f3 = open(readfile3, 'r')\n",
    "for line3 in f3:\n",
    "    image_lis3, label3 = line3[:-1].split('\\t')\n",
    "    image_list3.append(image_lis3)\n",
    "    labels3.append(label3)\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list3.pop(0)\n",
    "labels3.pop(0)\n",
    "dic3 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i3 in range(len(image_list3)): \n",
    "    dic3[image_list3[i3]] = labels3[i3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list3.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_train = {}\n",
    "k3 = 0\n",
    "for k3 in range(len(image_list3)): \n",
    "    dic_train[k3] = dic3[image_list3[k3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantes3 = {}\n",
    "for top3 in range(len(image_list3)):\n",
    "    if relevantes3.get(labels3[top3]):\n",
    "        relevantes3[labels3[top3]]=relevantes3[labels3[top3]]+1\n",
    "    else: \n",
    "        relevantes3[labels3[top3]] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista3 = []\n",
    "for image_name3 in image_list3:\n",
    "    lista3.append(os.path.join(params['root'],params['database'],\n",
    "                                     params['splittr'],\n",
    "                                     'images',image_name3.rstrip()+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i3=0\n",
    "imagen3 = []\n",
    "final3 = []\n",
    "for i3 in range(len(image_list3)):   \n",
    "    imagen3.append(image.load_img(lista3[i3], target_size=(224, 224)))\n",
    "    final3.append(image.img_to_array(imagen3[i3]))\n",
    "    final3[i3] = np.expand_dims(final3[i3], axis=0)\n",
    "    final3[i3] = preprocess_input(final3[i3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida3 = []\n",
    "k3 = 0\n",
    "for k3 in range(len(image_list3)):\n",
    "    salida3.append(model.predict(final3[k3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_val = np.asarray(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(descriptors_val, open(\"save_val.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imagen, open(\"save_img.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_test = np.asarray(salida2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(descriptors_test, open(\"save_test.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imagen2, open(\"save_img2.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_train = np.asarray(salida3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(descriptors_train, open(\"save_train.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imagen3, open(\"save_img3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dic_val,open(\"save_dic_val.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dic_test,open(\"save_dic_test.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dic_train,open(\"save_dic_train.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ajuntament': 75,\n",
       " 'castell_cartoixa': 75,\n",
       " 'catedral': 75,\n",
       " 'desconegut': 295,\n",
       " 'dona_treballadora': 74,\n",
       " 'escola_enginyeria': 75,\n",
       " 'estacio_nord': 75,\n",
       " 'farmacia_albinyana': 75,\n",
       " 'masia_freixa': 75,\n",
       " 'mercat_independencia': 75,\n",
       " 'mnactec': 75,\n",
       " 'societat_general': 75,\n",
       " 'teatre_principal': 75}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
